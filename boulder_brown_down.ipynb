{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Boulder Grasslands Phenology Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cartopy.crs as ccrs\n",
    "import earthpy as et\n",
    "import earthpy.earthexplorer as etee\n",
    "import earthpy.appeears as etapp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geoviews as gv\n",
    "from glob import glob\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import regionmask\n",
    "import rioxarray as rxr\n",
    "# import rasterio\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import zipfile\n",
    "import xarray as xr\n",
    "from xrspatial import zonal_stats\n",
    "\n",
    "from shapely.geometry import box, Polygon\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hv.extension('bokeh')\n",
    "gv.extension(\"bokeh\")\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data directory\n",
    "\n",
    "data_dir = os.path.join(et.io.HOME, et.io.DATA_NAME, 'boulder-grasslands')\n",
    "ndvi_dir = os.path.join(data_dir, 'ndvi-data')\n",
    "veg_type_dir = os.path.join(data_dir, 'veg-type-data')\n",
    "\n",
    "ndvi_processed_data_path = os.path.join(ndvi_dir, 'processed_data')\n",
    "\n",
    "for a_dir in [ndvi_dir, veg_type_dir, ndvi_processed_data_path]:\n",
    "        if not os.path.exists(a_dir):\n",
    "                os.makedirs(a_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download vegetation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Download for one chunk\n",
    "# veg_url = (\n",
    "#     \"https://gis.bouldercolorado.gov/ags_svr2/rest/services/osmp/OSMPVegetation/MapServer/1/query?where=OBJECTID%20%3E%3D%20{min_objectid}%20AND%20OBJECTID%20%3C%3D%20{max_objectid}&outFields=*&outSR=4326&f=geojson\"\n",
    "# )\n",
    "\n",
    "# user_agent = (\n",
    "#     'Mozilla/5.0 (X11; Linux x86_64; rv:60.0) '\n",
    "#     'Gecko/20100101 Firefox/81.0'\n",
    "# )\n",
    "# r = requests.get(url=veg_url.format(min_objectid=11444, max_objectid=11447), headers={'User-Agent': user_agent})\n",
    "\n",
    "# # Read GeoJSON data into a GeoDataFrame\n",
    "# geojson_data = r.json()\n",
    "\n",
    "# veg_gdf = gpd.GeoDataFrame.from_features(geojson_data['features'])\n",
    "\n",
    "# veg_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download vegetation type data if it does not exist\n",
    "\n",
    "print(\"Checking if data is downloaded...\")\n",
    "veg_type_path = os.path.join(veg_type_dir, 'veg_type.geojson')\n",
    "\n",
    "if os.path.exists(veg_type_path):\n",
    "    print(\"Data is already downloaded.\")  \n",
    "else: \n",
    "    print(\"Data is not downloaded. Initiating download...\")\n",
    "\n",
    "    # Define URL\n",
    "    veg_url = (\n",
    "        \"https://gis.bouldercolorado.gov/ags_svr2/rest/services/osmp/OSMPVegetation/MapServer/1/query?where=1%3D1&outFields=*&returnGeometry=false&returnIdsOnly=true&outSR=4326&f=json\"\n",
    "    )\n",
    "\n",
    "    # Mimic web browser\n",
    "    user_agent = (\n",
    "        'Mozilla/5.0 (X11; Linux x86_64; rv:60.0) '\n",
    "        'Gecko/20100101 Firefox/81.0'\n",
    "    )\n",
    "\n",
    "    # Download GEOJSON\n",
    "    r = requests.get(url=veg_url, headers={'User-Agent': user_agent})\n",
    "\n",
    "    # Read GeoJSON data into a GeoDataFrame\n",
    "    geojson_data = r.json()\n",
    "\n",
    "    # Extract the objectIDs (the indexes of the rows in the dataset)\n",
    "    objectid_list = geojson_data[\"objectIds\"]\n",
    "\n",
    "    # Define chunks\n",
    "    chunks = [\n",
    "        (objectid_list[i], \n",
    "            objectid_list[min(i + 1000,\n",
    "                                len(objectid_list)-1)]) \n",
    "                                for i in range(0, len(objectid_list), 1000)\n",
    "    ]\n",
    "    print(\"Data chunks identified.\")\n",
    "\n",
    "    ## Download data in chunks\n",
    "\n",
    "    # Create list\n",
    "    veg_list = []\n",
    "\n",
    "    # Due to the City of Boulder ArcGIS Hub limit of downloading\n",
    "    # a maximum of 1,000 items at a time,\n",
    "    # split the dataset into chunks and download the chunks individually.\n",
    "\n",
    "    # Download data for each chunk\n",
    "    for (min_objectid, max_objectid) in chunks:\n",
    "\n",
    "        print(\"Downloading chunk.\")\n",
    "\n",
    "        # Define url\n",
    "        veg_url = (\n",
    "            \"https://gis.bouldercolorado.gov/ags_svr2/rest/services/osmp/OSMPVegetation/MapServer/1/query?where=OBJECTID%20%3E%3D%20{min_objectid}%20AND%20OBJECTID%20%3C%3D%20{max_objectid}&outFields=*&outSR=4326&f=geojson\"\n",
    "        )\n",
    "\n",
    "        # Mimic web browser\n",
    "        user_agent = (\n",
    "            'Mozilla/5.0 (X11; Linux x86_64; rv:60.0) '\n",
    "            'Gecko/20100101 Firefox/81.0'\n",
    "        )\n",
    "\n",
    "        # Download chunk of data\n",
    "        r = requests.get(url=veg_url.format(min_objectid=min_objectid, max_objectid=max_objectid), headers={'User-Agent': user_agent})\n",
    "\n",
    "        # Read GeoJSON data into a GeoDataFrame\n",
    "        geojson_data = r.json()\n",
    "        veg_gdf = gpd.GeoDataFrame.from_features(geojson_data['features'])\n",
    "\n",
    "        # Add the chunk gdf to the list\n",
    "        veg_list.append(veg_gdf)\n",
    "\n",
    "        print(\"Done.\")\n",
    "\n",
    "    # Concatenate the chunk gdfs into one gdf\n",
    "    veg_gdf = pd.concat(veg_list)\n",
    "\n",
    "    # Save downloaded data to CSV in directory\n",
    "    veg_gdf.to_file(veg_type_path, driver='GeoJSON')\n",
    "    print(\"Saved data to GeoJSON.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download NDVI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vegetation data\n",
    "veg_gdf = gpd.read_file(veg_type_path)\n",
    "\n",
    "# Calculate the total bounds\n",
    "bounding_box = veg_gdf.total_bounds\n",
    "\n",
    "# Create a polygon from the bounding box\n",
    "minx, miny, maxx, maxy = bounding_box\n",
    "bounding_box_polygon = box(minx, miny, maxx, maxy)\n",
    "bounding_box_gdf = gpd.GeoDataFrame(geometry=[bounding_box_polygon],\n",
    "                                    crs=veg_gdf.crs)\n",
    "\n",
    "bounding_box_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test bbox code\n",
    "\n",
    "# bbox_map = bounding_box_gdf.hvplot(\n",
    "#     geo=True,\n",
    "#     line_color='black',\n",
    "#     fill_alpha=0,\n",
    "#     tiles='EsriImagery'\n",
    "# ).opts(\n",
    "#     width=800,\n",
    "#     height=800,\n",
    "#     show_legend=False  # Set legend to False to remove it\n",
    "# )\n",
    "\n",
    "# bbox_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AppeearsDownloader for MODIS NDVI data\n",
    "ndvi_downloader = etapp.AppeearsDownloader(\n",
    "    download_key=\"modis-ndvi\",\n",
    "    ea_dir=ndvi_dir,\n",
    "    product=\"MYD13Q1.061\",  # from list of APPEEARS datasts\n",
    "    layer=\"_250m_16_days_NDVI\",\n",
    "    start_date=\"01-01\",\n",
    "    end_date=\"12-31\",\n",
    "    recurring=True,\n",
    "    year_range=[2015, 2022],\n",
    "    polygon=bounding_box_gdf,\n",
    ")\n",
    "\n",
    "# Download files if the download directory does not exist\n",
    "if os.path.exists(ndvi_downloader.data_dir):\n",
    "    print(\"MODIS NDVI data is already downloaded.\")\n",
    "else:\n",
    "    print(\"Downloading MODIS NDVI data.\")\n",
    "    ndvi_downloader.download_files()\n",
    "\n",
    "ndvi_downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge NDVI data into a Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge arrays and cache result\n",
    "\n",
    "# Define NDVI processed data path\n",
    "ndvi_combined_path = os.path.join(ndvi_processed_data_path, \"ndvi_data.nc\")\n",
    "\n",
    "\n",
    "# Load and merge arrays only if the processed data has not already been created\n",
    "if os.path.exists(ndvi_combined_path):\n",
    "    print(\"NDVI data has already been merged and processed.\")\n",
    "else:\n",
    "    print(\"Merging and processing data.\")\n",
    "\n",
    "    # Generate list of data files\n",
    "    ndvi_path_list = glob(\n",
    "        os.path.join(ndvi_downloader.data_dir, \"*\", \"*NDVI*.tif\")\n",
    "    )\n",
    "\n",
    "    # Merge images into a single data array\n",
    "\n",
    "    doy_start = -19 # the character number of the start of doy in file name\n",
    "    doy_end = -12 # the character number of the end of doy in file name\n",
    "    scale_factor = 10000 # from MODIS data documentation\n",
    "\n",
    "    # Define a list\n",
    "    ndvi_da_list = []\n",
    "\n",
    "    # For every file (.tif image), add it to the list\n",
    "    for ndvi_path in ndvi_path_list:\n",
    "        # Get date from file name\n",
    "        doy = ndvi_path[doy_start:doy_end]\n",
    "\n",
    "        # Define the date variable as the doy in file name\n",
    "        date = pd.to_datetime(doy, format='%Y%j')\n",
    "\n",
    "        # Open dataset\n",
    "        da = rxr.open_rasterio(ndvi_path,\n",
    "                            # masked=True changes specific excluded\n",
    "                            # values from the metadata to NaN values\n",
    "                            masked=True).squeeze()\n",
    "\n",
    "        # Prepare to concatenate: Add date dimension and clean up metadata\n",
    "        da = da.assign_coords({'date': date})\n",
    "        da = da.expand_dims({'date': 1})\n",
    "        da.name = 'NDVI'\n",
    "\n",
    "        # Divide by scale factor\n",
    "        da = da / scale_factor\n",
    "\n",
    "        # Add the DataArray to the end of the accumulator list\n",
    "        ndvi_da_list.append(da)\n",
    "        print(\"Added .tif data to data array list.\")\n",
    "\n",
    "    # Stack arrays into time series\n",
    "    ndvi_dataset = xr.combine_by_coords(ndvi_da_list, coords=[\"date\"])\n",
    "    print(\"Stacked arrays into data set.\")\n",
    "\n",
    "    # Cache the ndvi dataset as a netCDF\n",
    "    ndvi_dataset.to_netcdf(path=ndvi_combined_path)\n",
    "    print(\"Created netCDF file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View vegetation data\n",
    "\n",
    "veg_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with base plotting\n",
    "\n",
    "veg_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NDVI data\n",
    "\n",
    "ndvi_ds = xr.open_dataset(ndvi_combined_path)\n",
    "ndvi_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDVI [should take values between -1.0 and 1.0.](https://ipad.fas.usda.gov/cropexplorer/Definitions/spotveg.htm) Verify that NDVI falls within expected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate histogram of NDVI\n",
    "\n",
    "ndvi_ds.NDVI.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NDVI in 2022 to test\n",
    "\n",
    "# Select NDVI in 2022 June\n",
    "ndvi_2022_da = (ndvi_ds\n",
    "    .sel(date = '2022-06')\n",
    "    .mean('date')\n",
    "    .NDVI)\n",
    "\n",
    "# Plot with matplotlib\n",
    "ndvi_2022_da.plot(cmap=plt.colormaps['PiYG'])\n",
    "veg_gdf.plot(facecolor='none', ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize NDVI patterns over time\n",
    "ndvi_time = gv.Dataset(ndvi_ds, kdims=['x', 'y', 'date'], vdims=['NDVI'])\n",
    "\n",
    "# Create a GeoViews plot\n",
    "ndvi_plot = ndvi_time.to(gv.Image).opts(cmap='greens', colorbar=True, alpha=0.8, tools=['hover'], width=700, height=500)\n",
    "ndvi_ref_plot = ndvi_plot * gv.tile_sources.OSM()\n",
    "\n",
    "ndvi_ref_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, only visualize NDVI within the vegetation polygon boundaries (i.e., ignore all NDVI pixels for which we will not calculate brown-down such as urban and agricultural lands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before clipping, check CRS\n",
    "print(veg_gdf.crs)\n",
    "print(ndvi_ds.rio.crs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip raster to polygons\n",
    "ndvi_ds_veg_only = ndvi_ds.rio.clip(veg_gdf.geometry, all_touched=True)\n",
    "\n",
    "print(ndvi_ds_veg_only.rio.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_touched option for the clip if that's what's causing the NAs\n",
    "\n",
    "Can clip to debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clipped data\n",
    "\n",
    "# Calculate NDVI in 2022 June\n",
    "ndvi_2022_clipped_da = (ndvi_ds_veg_only\n",
    "    .sel(date = '2022-06')\n",
    "    .mean('date')\n",
    "    .NDVI)\n",
    "\n",
    "# Plot with matplotlib\n",
    "ndvi_2022_clipped_da.plot(cmap=plt.colormaps['PiYG'])\n",
    "veg_gdf.plot(facecolor='none', ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize NDVI over time\n",
    "ndvi_time_veg_only = gv.Dataset(ndvi_ds_veg_only, kdims=['x', 'y', 'date'], vdims=['NDVI'])\n",
    "\n",
    "# Create a GeoViews plot\n",
    "ndvi_veg_only_plot = ndvi_time_veg_only.to(gv.Image).opts(cmap='viridis_r', colorbar=True, alpha=0.8, tools=['hover'], width=700, height=500)\n",
    "ndvi_veg_only_plot * gv.tile_sources.EsriImagery()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate brown-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentile thresholds\n",
    "\n",
    "thresholds_df = (ndvi_ds.to_dataframe()\n",
    "                  .reset_index()\n",
    "                  # Select only June-December dates - we are \n",
    "                  # not interested in green-up after snowmelt\n",
    "                  .loc[lambda x: (x['date'].dt.month >= 6) & (x['date'].dt.month <= 12)]\n",
    "                  # Convert the data coordinate to column\n",
    "                  .assign(year=lambda x: x['date'].dt.year)\n",
    "                  # Calculate 10th percentile value\n",
    "                  .groupby(['x', 'y', 'year'])\n",
    "                  .agg(threshold=('NDVI', lambda x: x.quantile(0.1)))\n",
    "\n",
    ")\n",
    "thresholds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the 10th percentile dates of greenness\n",
    "\n",
    "dates_da = (ndvi_ds_veg_only.to_dataframe()\n",
    "            .reset_index()\n",
    "            # Select only June-December dates - we are \n",
    "            # not interested in green-up after snowmelt\n",
    "            .loc[lambda x: (x['date'].dt.month >= 6) & (x['date'].dt.month <= 12)]\n",
    "            # Convert the data coordinate to column\n",
    "            .assign(year=lambda x: x['date'].dt.year)\n",
    "            # Left-join the thresholds by columns x, y, year\n",
    "            .merge(thresholds_df, on=['x', 'y', 'year'], how='left')\n",
    "            # Create a new column for TF the ndvi value falls at or under the threshold\n",
    "            .assign(is_below_threshold=lambda x: x['NDVI'] <= x['threshold'])\n",
    "            # Remove all False columns\n",
    "            .loc[lambda x: x['is_below_threshold']]\n",
    "            # Group by x, y, year, select lowest dates\n",
    "            .groupby(['x', 'y', 'year'])\n",
    "            # .agg(min_date=('date', np.nanmin))\n",
    "            .agg(min_date=('date', 'min'))\n",
    "            .to_xarray()\n",
    "\n",
    ")\n",
    "\n",
    "# Create day of year from date column\n",
    "dates_da['day_of_year'] = dates_da.min_date.dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could run reproject match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in a CRS\n",
    "\n",
    "dates_da_crs = dates_da.rio.write_crs(ndvi_ds_veg_only.rio.crs)\n",
    "print(dates_da_crs.rio.crs)\n",
    "dates_da_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test plot\n",
    "\n",
    "print(veg_gdf.crs)\n",
    "print(dates_da_crs.rio.crs)\n",
    "\n",
    "# Pick 2022 June\n",
    "dates_2022_da_crs = (dates_da_crs\n",
    "    .sel(year = 2022)\n",
    "    .day_of_year)\n",
    "\n",
    "# Plot with matplotlib\n",
    "dates_2022_da_crs.plot(x='x', y='y', cmap=plt.colormaps['PiYG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Interactive Map of brown-down dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_veg_gdf = veg_gdf.copy()  # Make a copy to avoid modifying the original data\n",
    "simplified_veg_gdf['geometry'] = veg_gdf['geometry'].simplify(tolerance=0.0001)  # Adjust the tolerance as needed\n",
    "\n",
    "# Convert the 'STRING_COLUMN' to a string type\n",
    "simplified_veg_gdf['MACROGROUP'] = simplified_veg_gdf['MACROGROUP'].astype(str)\n",
    "\n",
    "# Create veg polygons map\n",
    "veg_map = simplified_veg_gdf.hvplot(\n",
    "    geo=True,\n",
    "    line_color='black',\n",
    "    fill_alpha=0,\n",
    "    tiles='EsriImagery',\n",
    "    hover_cols=['MACROGROUP']\n",
    ").opts(\n",
    "    width=500,\n",
    "    height=800,\n",
    "    show_legend=False,  # Set legend to False to remove it\n",
    "    tools=['hover']\n",
    ")\n",
    "\n",
    "veg_map\n",
    "\n",
    "# veg_map = gv.Polygons(simplified_veg_gdf, vdims=['SCIENTIFICNAME']\n",
    "#     # tiles='EsriImagery'\n",
    "# ).opts(\n",
    "#     width=500,\n",
    "#     height=800,\n",
    "#     show_legend=False,  # Set legend to False to remove it\n",
    "#     color=None\n",
    "#     #tools=['hover']\n",
    "# )\n",
    "\n",
    "# veg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the xarray DataArray to a GeoViews object\n",
    "dates_gvds = gv.Dataset(dates_da, kdims=['x', 'y', 'year'], vdims=['day_of_year'])\n",
    "\n",
    "\n",
    "# Create a GeoViews plot\n",
    "dates_plot = dates_gvds.to(gv.Image).opts(cmap='viridis_r',\n",
    "                                          colorbar=True,\n",
    "                                          alpha=0.5,\n",
    "                                          width=600,\n",
    "                                          height=800,\n",
    "                                          show_legend=False)\n",
    "\n",
    "\n",
    "dates_veg_plot = (dates_plot  \n",
    "             * veg_map).opts(tools=['hover'],\n",
    "                                    width=600,\n",
    "                                    height=800,\n",
    "                                    show_legend=False)\n",
    "\n",
    "# Display plot\n",
    "dates_veg_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculate zonal means for each polygon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only day of year\n",
    "dates_array = dates_da['day_of_year']\n",
    "\n",
    "# Create mask of multiple regions from shapefile\n",
    "veg_mask = regionmask.mask_3D_geopandas(\n",
    "    veg_gdf,\n",
    "    dates_array.x,\n",
    "    dates_array.y,\n",
    "    drop=True,\n",
    "    overlap=True,\n",
    "    numbers=\"OBJECTID\"\n",
    ")\n",
    "\n",
    "# Apply mask on dates data\n",
    "dates_array = dates_array.where(veg_mask)\n",
    "\n",
    "\n",
    "# Calculate means by group\n",
    "veg_avg_dates_ds = (dates_array\n",
    "                    .groupby(\"region\")\n",
    "                    .mean([\"x\",\"y\"])\n",
    ")\n",
    "\n",
    "# Convert to dataframe\n",
    "veg_avg_dates_df = (veg_avg_dates_ds.to_dataframe()\n",
    "                    .apply(lambda x: x.dropna())\n",
    ")\n",
    "\n",
    "veg_avg_dates_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a way to ignore NaNs in this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test plot\n",
    "\n",
    "veg_avg_dates_df['day_of_year'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(veg_avg_dates_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge average dates by vegetation patch \n",
    "# with original vegetation to retrieve geometry\n",
    "veg_avg_dates_gdf = (veg_avg_dates_df\n",
    "    .reset_index()\n",
    "    .merge(simplified_veg_gdf, left_on='region', right_on='OBJECTID', how='left')\n",
    "    .sort_values(by=['region', 'year'])\n",
    "    #.assign(date_column=pd.to_datetime(veg_avg_dates_gdf['day_of_year'], format='%j', errors='coerce'))\n",
    ")\n",
    "\n",
    "# veg_avg_dates_gdf\n",
    "# Remove rows with NaN values for plotting\n",
    "veg_avg_dates_gdf_nonans = veg_avg_dates_gdf.loc[veg_avg_dates_gdf['day_of_year'].notna()]\n",
    "\n",
    "veg_avg_dates_gdf_nonans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seaborn to create a faceted histogram\n",
    "sns.set(style=\"whitegrid\")\n",
    "g = sns.FacetGrid(veg_avg_dates_gdf_nonans, col=\"MACROGROUP\", col_wrap=2, height=4, sharex=False)\n",
    "\n",
    "# Map the histogram to each facet\n",
    "g.map(plt.hist, \"day_of_year\", bins=5, edgecolor='black')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set geometry\n",
    "veg_avg_dates_gdf_nonans = veg_avg_dates_gdf_nonans.set_geometry('geometry')\n",
    "\n",
    "# Convert 'year' to datetime if it's not already\n",
    "veg_avg_dates_gdf_nonans['year'] = pd.to_datetime(veg_avg_dates_gdf_nonans['year'], errors='coerce')\n",
    "\n",
    "time_slider_plot = veg_avg_dates_gdf_nonans.hvplot.polygons(\n",
    "    geo=True, \n",
    "    c='day_of_year', \n",
    "    cmap='viridis', \n",
    "    project=True,\n",
    "    titles='year'   # Specify the time dimension\n",
    ").opts(\n",
    "    frame_width=600, \n",
    "    frame_height=400,\n",
    "    title='Choropleth with Time Slider',\n",
    "    framewise=True,  # Enable the time slider\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "time_slider_plot * gv.tile_sources.EsriImagery\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
